import streamlit as st
import numpy as np
import io
import tempfile
import os
from pydub import AudioSegment, effects
from pydub.silence import detect_nonsilent
import noisereduce as nr
from scipy.signal import butter, lfilter
import plotly.graph_objects as go
import plotly.express as px

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏
st.set_page_config(
    page_title="–ê—É–¥—ñ–æ –†–µ–∫–æ—Ä–¥–µ—Ä —Ç–∞ –†–µ–¥–∞–∫—Ç–æ—Ä v1.0.4",
    page_icon="üéµ",
    layout="wide"
)

# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–±—Ä—ñ–∑–∫–∏ —Ç–∏—à—ñ
def trim_silence(audio, silence_thresh=-40, min_silence_len=100):
    nonsilent = detect_nonsilent(audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)
    if not nonsilent:
        return audio
    start_trim = nonsilent[0][0]
    end_trim = nonsilent[-1][1]
    return audio[start_trim:end_trim]

# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –µ–∫–≤–∞–ª–∞–π–∑–µ—Ä–∞
def butter_bandpass(lowcut, highcut, fs, order=2):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    return b, a

def apply_equalizer(samples, fs, gains):
    # 5 —Å–º—É–≥: 60, 250, 1000, 4000, 16000 –ì—Ü
    bands = [(20, 120), (120, 500), (500, 2000), (2000, 8000), (8000, 20000)]
    out = np.zeros_like(samples)
    for i, (low, high) in enumerate(bands):
        b, a = butter_bandpass(low, high, fs)
        filtered = lfilter(b, a, samples)
        gain = 10 ** (gains[i] / 20)
        out += filtered * gain
    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—ñ—Å–ª—è –µ–∫–≤–∞–ª–∞–π–∑–µ—Ä–∞
    if np.max(np.abs(out)) > 0:
        out = out / np.max(np.abs(out)) * 0.95
    return out

# –ì–æ–ª–æ–≤–Ω–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
st.title("üéµ –ê—É–¥—ñ–æ –†–µ–∫–æ—Ä–¥–µ—Ä —Ç–∞ –†–µ–¥–∞–∫—Ç–æ—Ä v1.0.4")
st.markdown("---")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å—Ç–∞–Ω—É —Å–µ—Å—ñ—ó
if 'audio_data' not in st.session_state:
    st.session_state.audio_data = None
if 'processed_audio' not in st.session_state:
    st.session_state.processed_audio = None
if 'history' not in st.session_state:
    st.session_state.history = []

# –ë–æ–∫–æ–≤–∞ –ø–∞–Ω–µ–ª—å –¥–ª—è –µ–∫–≤–∞–ª–∞–π–∑–µ—Ä–∞
with st.sidebar:
    st.header("üéõÔ∏è –ï–∫–≤–∞–ª–∞–π–∑–µ—Ä")
    
    # –°–ª–∞–π–¥–µ—Ä–∏ –¥–ª—è 5 —Å–º—É–≥
    eq_gains = []
    eq_freqs = [60, 250, 1000, 4000, 16000]
    
    for i, freq in enumerate(eq_freqs):
        gain = st.slider(f'{freq} –ì—Ü', -12, 12, 0, 1, key=f'eq_{i}')
        eq_gains.append(gain)
    
    st.markdown("---")
    
    # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è
    st.header("üéÆ –£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è")
    
    if st.button("üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∞—É–¥—ñ–æ", use_container_width=True):
        st.info("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É –Ω–∏–∂—á–µ")
    
    if st.button("üîÑ –°–∫–∞—Å—É–≤–∞—Ç–∏", use_container_width=True):
        if st.session_state.history:
            st.session_state.audio_data = st.session_state.history.pop()
            st.rerun()
    
    if st.button("üíæ –ó–±–µ—Ä–µ–≥—Ç–∏", use_container_width=True):
        if st.session_state.audio_data is not None:
            st.success("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É –Ω–∏–∂—á–µ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è")

# –û—Å–Ω–æ–≤–Ω–∞ –æ–±–ª–∞—Å—Ç—å
col1, col2 = st.columns([2, 1])

with col1:
    st.header("üìä –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∞—É–¥—ñ–æ")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É
    uploaded_file = st.file_uploader(
        "–í–∏–±–µ—Ä—ñ—Ç—å –∞—É–¥—ñ–æ —Ñ–∞–π–ª", 
        type=['wav', 'mp3', 'flac', 'ogg'],
        help="–ü—ñ–¥—Ç—Ä–∏–º—É—é—Ç—å—Å—è —Ñ–æ—Ä–º–∞—Ç–∏: WAV, MP3, FLAC, OGG"
    )
    
    if uploaded_file is not None:
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ
            audio_bytes = uploaded_file.read()
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                tmp_file.write(audio_bytes)
                tmp_file_path = tmp_file.name
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ —á–µ—Ä–µ–∑ pydub
            audio = AudioSegment.from_file(tmp_file_path)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –≤ –º–æ–Ω–æ
            if audio.channels == 2:
                audio = audio.set_channels(1)
            
            # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –∑—Ä–∞–∑–∫—ñ–≤
            samples = np.array(audio.get_array_of_samples()).astype(np.float32)
            samples = samples / np.max(np.abs(samples))  # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
            
            st.session_state.audio_data = {
                'samples': samples,
                'fs': audio.frame_rate,
                'duration': len(audio) / 1000.0,
                'filename': uploaded_file.name
            }
            
            # –û—á–∏—â–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
            os.unlink(tmp_file_path)
            
            st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {uploaded_file.name}")
            
        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {str(e)}")
    
    # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫–∞
    if st.session_state.audio_data is not None:
        samples = st.session_state.audio_data['samples']
        fs = st.session_state.audio_data['fs']
        duration = st.session_state.audio_data['duration']
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —á–∞—Å–æ–≤–æ—ó –æ—Å—ñ
        t = np.linspace(0, duration, len(samples))
        
        # –ì—Ä–∞—Ñ—ñ–∫ –∞—É–¥—ñ–æ
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=t, 
            y=samples, 
            mode='lines',
            name='–ê—É–¥—ñ–æ —Å–∏–≥–Ω–∞–ª',
            line=dict(color='blue', width=1)
        ))
        
        fig.update_layout(
            title="–•–≤–∏–ª—è –∞—É–¥—ñ–æ",
            xaxis_title="–ß–∞—Å (—Å–µ–∫—É–Ω–¥–∏)",
            yaxis_title="–ê–º–ø–ª—ñ—Ç—É–¥–∞",
            height=400,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ —Ñ–∞–π–ª
        st.info(f"üìä –¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {duration:.2f} —Å–µ–∫ | –ß–∞—Å—Ç–æ—Ç–∞: {fs} –ì—Ü | –ó—Ä–∞–∑–∫—ñ–≤: {len(samples)}")

with col2:
    st.header("üéµ –í—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è")
    
    if st.session_state.audio_data is not None:
        # –ö–Ω–æ–ø–∫–∏ –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è
        col_play1, col_play2 = st.columns(2)
        
        with col_play1:
            if st.button("‚ñ∂Ô∏è –í—ñ–¥—Ç–≤–æ—Ä–∏—Ç–∏", use_container_width=True):
                st.audio(uploaded_file, format='audio/wav')
        
        with col_play2:
            if st.button("üéõÔ∏è –ó EQ", use_container_width=True):
                # –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –µ–∫–≤–∞–ª–∞–π–∑–µ—Ä–∞
                samples = st.session_state.audio_data['samples']
                fs = st.session_state.audio_data['fs']
                
                eq_samples = apply_equalizer(samples, fs, eq_gains)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –Ω–∞–∑–∞–¥ –≤ –∞—É–¥—ñ–æ
                eq_audio = (eq_samples * 32767).astype(np.int16)
                audio_segment = AudioSegment(
                    eq_audio.tobytes(),
                    frame_rate=fs,
                    sample_width=2,
                    channels=1
                )
                
                # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                    audio_segment.export(tmp_file.name, format="wav")
                    with open(tmp_file.name, "rb") as f:
                        st.audio(f.read(), format='audio/wav')
                    os.unlink(tmp_file.name)
        
        st.markdown("---")
        
        # –û–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ
        st.header("üîß –û–±—Ä–æ–±–∫–∞")
        
        if st.button("üßπ –û–±—Ä–æ–±–∏—Ç–∏ –∞—É–¥—ñ–æ", use_container_width=True):
            with st.spinner("–û–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ..."):
                # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ —ñ—Å—Ç–æ—Ä—ñ—é
                st.session_state.history.append(st.session_state.audio_data.copy())
                
                samples = st.session_state.audio_data['samples']
                fs = st.session_state.audio_data['fs']
                
                # 1. –û–±—Ä—ñ–∑–∫–∞ —Ç–∏—à—ñ
                audio_segment = AudioSegment(
                    (samples * 32767).astype(np.int16).tobytes(),
                    frame_rate=fs,
                    sample_width=2,
                    channels=1
                )
                
                trimmed = trim_silence(audio_segment, silence_thresh=audio_segment.dBFS-16, min_silence_len=100)
                proc_samples = np.array(trimmed.get_array_of_samples()).astype(np.float32)
                proc_samples = proc_samples / np.max(np.abs(proc_samples))
                
                # 2. –í–∏–¥–∞–ª–µ–Ω–Ω—è —à—É–º—É
                reduced = nr.reduce_noise(y=proc_samples, sr=fs)
                
                # 3. –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
                normed = effects.normalize(AudioSegment(
                    (reduced * 32767).astype(np.int16).tobytes(),
                    frame_rate=fs,
                    sample_width=2,
                    channels=1
                ))
                
                # 4. –ï–∫–≤–∞–ª–∞–π–∑–µ—Ä
                eq_samples = np.array(normed.get_array_of_samples()).astype(np.float32)
                eq_samples = eq_samples / np.max(np.abs(eq_samples))
                eq_samples = apply_equalizer(eq_samples, fs, eq_gains)
                
                # –û–Ω–æ–≤–ª–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
                st.session_state.audio_data['samples'] = eq_samples
                st.session_state.processed_audio = eq_samples
                
                st.success("‚úÖ –ê—É–¥—ñ–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ!")
                st.rerun()
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –æ–±—Ä–æ–±–ª–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
        if st.session_state.processed_audio is not None:
            st.markdown("---")
            st.header("üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –≤ –∞—É–¥—ñ–æ —Å–µ–≥–º–µ–Ω—Ç
            processed_samples = st.session_state.processed_audio
            fs = st.session_state.audio_data['fs']
            
            audio_segment = AudioSegment(
                (processed_samples * 32767).astype(np.int16).tobytes(),
                frame_rate=fs,
                sample_width=2,
                channels=1
            )
            
            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –±—É—Ñ–µ—Ä
            buffer = io.BytesIO()
            audio_segment.export(buffer, format="wav")
            buffer.seek(0)
            
            st.download_button(
                label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –æ–±—Ä–æ–±–ª–µ–Ω–µ –∞—É–¥—ñ–æ",
                data=buffer.getvalue(),
                file_name="processed_audio.wav",
                mime="audio/wav",
                use_container_width=True
            )
    
    else:
        st.info("üìÅ –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –∞—É–¥—ñ–æ —Ñ–∞–π–ª –¥–ª—è –ø–æ—á–∞—Ç–∫—É —Ä–æ–±–æ—Ç–∏")

# –ü—ñ–¥–≤–∞–ª
st.markdown("---")
st.markdown("üéµ **–ê—É–¥—ñ–æ –†–µ–∫–æ—Ä–¥–µ—Ä —Ç–∞ –†–µ–¥–∞–∫—Ç–æ—Ä v1.0.4** - –°—Ç–≤–æ—Ä–µ–Ω–æ –∑ Streamlit")
st.markdown("üí° **–§—É–Ω–∫—Ü—ñ—ó**: –û–±—Ä—ñ–∑–∫–∞ —Ç–∏—à—ñ, –≤–∏–¥–∞–ª–µ–Ω–Ω—è —à—É–º—É, –µ–∫–≤–∞–ª–∞–π–∑–µ—Ä, –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è")
st.markdown("üîß **–ù–æ–≤—ñ —Ñ—É–Ω–∫—Ü—ñ—ó v1.0.4**: –ü–æ–∫—Ä–∞—â–µ–Ω–æ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–Ω—è, –¥–æ–¥–∞–Ω–æ –∫–Ω–æ–ø–∫—É '–í—ñ–¥—Ç–≤–æ—Ä–∏—Ç–∏ –∑ EQ'")
